{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devoir : scrapping de l'ensemble des produits sur opendata.org.\n",
    "https://fr.openfoodfacts.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Présenté par : \n",
    "| Prénoms       |     Nom         |   \n",
    "| ------------- |: -------------: |\n",
    "| Amadou lamarana      | DIALLO               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procédures de récupération des données\n",
    "1. Récupérer les urls qui pointe sur toutes ces pages i.e (https://fr.openfoodfacts.org/3) la 3ieme page\n",
    "2. Récuperer les urls des produits contenu dans chacune de ces pages\n",
    "3. Récupération des balises qui contiennent l'information pertinente (mentionnée ci dessous) et création d'une liste avec l'ensemble de toutes ces informations par start-up\n",
    "4. Création du Dataframe et l'export sous CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Opendata\n",
    "## import des modules nécessaires\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * liens principaux:\n",
    "        * BASE_URL = https://fr.openfoodfacts.org : page principale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://fr.openfoodfacts.org\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 1 : Récupérer les urls qui pointe sur toutes ces pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperer_urls_page():\n",
    "    \n",
    "    import re\n",
    "    \"\"\"\n",
    "        * Cette fonction retourne la liste des pages du site \n",
    "        * Cette liste initialisé avec l'url de valeur BASE_URL\n",
    "        * Une requête html avec ** request.get(BASE_URL)** pour tenter de récuperer le contenu de l'accueil\n",
    "        * Si la page est accessible, une série de manipulation avec BeautifoulSoup sera déclenchée pour \n",
    "        * suivant le format de liens, BASE_URL/n avec n le numéro de page, nous allons itérer \n",
    "            en tenant compte du numéro de la dernière page disponible sur le site.\n",
    "    @return list: urls\n",
    "    \"\"\"\n",
    "    #Initiate urls \n",
    "    urls= [BASE_URL] ## url de base initialisé avec le lien d'accueil du site (lien de base)\n",
    "    accueil = requests.get(BASE_URL) ## request html \n",
    "    if accueil.status_code == requests.codes.ok: ## All is OK (codeResponse = 200)\n",
    "        ## parser html\n",
    "        bs = BeautifulSoup(accueil.text, 'html.parser') \n",
    "        ## la pagination est accessible par la balise 'ul' et par l'identifiant \"pages\"\n",
    "        ulPages = bs.find('ul',id='pages')\n",
    "        ## récupérer les éléments de la pagination avec la balise 'li'\n",
    "        page = ulPages.findAll('li', class_='')\n",
    "        ## extrait avec le module :'re' des numéros de pages qui seront stockés dans une liste \"numeros\"\n",
    "        numeros = [ int(n.text) for n in page if n.text in re.findall('[0-9]*', n.text)]\n",
    "        derniere_page = max(numeros)\n",
    "        for i in range(2,derniere_page+1):\n",
    "            url = BASE_URL+'/'+str(i)\n",
    "            urls.append(url)\n",
    "    return urls\n",
    "#print(recuperer_urls_page())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Etape 2:  Récuperer les urls des produits contenu dans chacune de ces pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Etape 2.1:  Récuperer les urls des produits contenu dans une page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recuperer_url_produits_page(url_page):\n",
    "    \"\"\"Focntion qui renvoie les urls des produits listé dans la page du lien passé en paramètre\"\"\"\n",
    "    page = requests.get(url_page)\n",
    "    if page.status_code == requests.codes.ok:\n",
    "        bs = BeautifulSoup(page.text, 'html.parser')\n",
    "        bloc_produits = bs.find('ul', class_ ='products')\n",
    "        #print(bs)\n",
    "        les_produits = bloc_produits.findAll('li',class_='')\n",
    "        urls_produits = [BASE_URL+url.find(\"a\")['href'] for url in les_produits]\n",
    "    return urls_produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  #####  ETAPE 2. 2  Recupérer les urls de tous des produits de toute les pages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recuperer_urls_produits_site(urls_pages):\n",
    "    \"\"\"Focntion qui récupére les liens des produits du site\n",
    "        * Nous utilisons la fonction \"recuperer_urls_page\" pour avoir les liens des pages;\n",
    "        * Nous utilisons la fonction \"recuperer_url_produits_page\"  pour récupérer \n",
    "        les liens des produits par page\n",
    "        @return list: urls_produits\n",
    "    \"\"\"\n",
    "    urls_produits =[]\n",
    "    ## les produits par page\n",
    "    for page in urls_pages:\n",
    "        #time.sleep(random.uniform(0.2,0.5))\n",
    "        lien_produits = recuperer_url_produits_page(page)\n",
    "        \n",
    "        urls_produits = urls_produits + lien_produits\n",
    "    return urls_produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = recuperer_urls_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recuperer les urls des produits, enregistrer à la variable urls_produits\n",
    "urls_produits_site = recuperer_urls_produits_site(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls_produits_site = url_0_1000 + url_1000_2000 + url_2000_3000+ url_3000_4000+url_4000_5000 +url_5000_6000+url_6000_7000+url_7000_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798000"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls_produits_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url = pd.DataFrame(urls_produits_site)\n",
    "df_url.columns=['url_product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_url.to_csv('url_product',index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urls_produits_site = pd.read_csv('url_product.csv')\n",
    "urls_produits = list(df_urls_produits_site['url_product'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Etape 3 : Recupération des informations des produits "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
